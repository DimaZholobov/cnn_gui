{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь до тренировочного датасета\n",
    "train_dir = \"D:\\\\python\\\\guicore-alpha\\\\gui-core-alpha-70-30\\\\training\"\n",
    "# Путь до датасета валидации\n",
    "val_dir = \"D:\\\\python\\\\guicore-alpha\\\\gui-core-alpha-70-30\\\\validation\"\n",
    "# Размеры изображения\n",
    "img_width, img_height = 100, 100\n",
    "# Размер тензора (размеры изображения + количество цветов)\n",
    "input_shape = (img_width, img_height, 3)\n",
    "# Количество эпох\n",
    "epochs = 55\n",
    "# Размер мини-выборки\n",
    "batch_size = 10\n",
    "# Количество изображений для обучения\n",
    "nb_train_samples = 232\n",
    "# Количество изображений для проверки\n",
    "nb_validation_samples = 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение модели (стек слоёв)\n",
    "model = Sequential()\n",
    "# Добавление слоёв свёртки\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Добавление остальных слоёв и функций активации\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 47, 47, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 438,694\n",
      "Trainable params: 438,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 232 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 1.7799 - accuracy: 0.2477 - val_loss: 1.6948 - val_accuracy: 0.2000\n",
      "Epoch 2/55\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 1.6244 - accuracy: 0.2748 - val_loss: 1.6073 - val_accuracy: 0.2667\n",
      "Epoch 3/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 1.5654 - accuracy: 0.3108 - val_loss: 1.5692 - val_accuracy: 0.3111\n",
      "Epoch 4/55\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 1.4466 - accuracy: 0.3919 - val_loss: 1.3939 - val_accuracy: 0.4222\n",
      "Epoch 5/55\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 1.3239 - accuracy: 0.5180 - val_loss: 1.3437 - val_accuracy: 0.4889\n",
      "Epoch 6/55\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 1.3010 - accuracy: 0.4640 - val_loss: 1.2785 - val_accuracy: 0.5556\n",
      "Epoch 7/55\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 1.1583 - accuracy: 0.5541 - val_loss: 1.1307 - val_accuracy: 0.5444\n",
      "Epoch 8/55\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 1.1251 - accuracy: 0.5957 - val_loss: 1.5272 - val_accuracy: 0.5667\n",
      "Epoch 9/55\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 1.3531 - accuracy: 0.5180 - val_loss: 1.2728 - val_accuracy: 0.5444\n",
      "Epoch 10/55\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 1.1674 - accuracy: 0.5180 - val_loss: 1.2152 - val_accuracy: 0.5111\n",
      "Epoch 11/55\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 1.0571 - accuracy: 0.5811 - val_loss: 1.4848 - val_accuracy: 0.4667\n",
      "Epoch 12/55\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.9763 - accuracy: 0.6126 - val_loss: 1.1604 - val_accuracy: 0.5667\n",
      "Epoch 13/55\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.8924 - accuracy: 0.6577 - val_loss: 1.1849 - val_accuracy: 0.6000\n",
      "Epoch 14/55\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.7966 - accuracy: 0.6802 - val_loss: 1.0195 - val_accuracy: 0.5889\n",
      "Epoch 15/55\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.7346 - accuracy: 0.7027 - val_loss: 1.2739 - val_accuracy: 0.5667\n",
      "Epoch 16/55\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6740 - accuracy: 0.7207 - val_loss: 1.6433 - val_accuracy: 0.5778\n",
      "Epoch 17/55\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.8019 - accuracy: 0.6622 - val_loss: 1.0945 - val_accuracy: 0.5889\n",
      "Epoch 18/55\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.6464 - accuracy: 0.7793 - val_loss: 1.5959 - val_accuracy: 0.5889\n",
      "Epoch 19/55\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.6400 - accuracy: 0.7658 - val_loss: 1.4133 - val_accuracy: 0.5889\n",
      "Epoch 20/55\n",
      "23/23 [==============================] - 2s 75ms/step - loss: 0.6285 - accuracy: 0.7432 - val_loss: 1.2637 - val_accuracy: 0.6333\n",
      "Epoch 21/55\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5442 - accuracy: 0.8108 - val_loss: 1.4918 - val_accuracy: 0.6111\n",
      "Epoch 22/55\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.5154 - accuracy: 0.8063 - val_loss: 1.4200 - val_accuracy: 0.5778\n",
      "Epoch 23/55\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.5104 - accuracy: 0.7838 - val_loss: 1.2551 - val_accuracy: 0.6111\n",
      "Epoch 24/55\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.4980 - accuracy: 0.7883 - val_loss: 1.7106 - val_accuracy: 0.6111\n",
      "Epoch 25/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.4785 - accuracy: 0.8063 - val_loss: 1.4007 - val_accuracy: 0.6111\n",
      "Epoch 26/55\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.3333 - accuracy: 0.8874 - val_loss: 3.2271 - val_accuracy: 0.5889\n",
      "Epoch 27/55\n",
      "23/23 [==============================] - 2s 81ms/step - loss: 0.5770 - accuracy: 0.7613 - val_loss: 1.4099 - val_accuracy: 0.6000\n",
      "Epoch 28/55\n",
      "23/23 [==============================] - 2s 73ms/step - loss: 0.4058 - accuracy: 0.8333 - val_loss: 1.3787 - val_accuracy: 0.5889\n",
      "Epoch 29/55\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.4799 - accuracy: 0.7838 - val_loss: 1.5313 - val_accuracy: 0.6111\n",
      "Epoch 30/55\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.3812 - accuracy: 0.8649 - val_loss: 1.8764 - val_accuracy: 0.6111\n",
      "Epoch 31/55\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.3493 - accuracy: 0.8784 - val_loss: 1.8628 - val_accuracy: 0.6222\n",
      "Epoch 32/55\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.3184 - accuracy: 0.8829 - val_loss: 2.0327 - val_accuracy: 0.6111\n",
      "Epoch 33/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.3060 - accuracy: 0.8649 - val_loss: 2.6391 - val_accuracy: 0.6111\n",
      "Epoch 34/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.4876 - accuracy: 0.8378 - val_loss: 2.0121 - val_accuracy: 0.6222\n",
      "Epoch 35/55\n",
      "23/23 [==============================] - 2s 78ms/step - loss: 0.4458 - accuracy: 0.8604 - val_loss: 1.9855 - val_accuracy: 0.6111\n",
      "Epoch 36/55\n",
      "23/23 [==============================] - 2s 77ms/step - loss: 0.3206 - accuracy: 0.8649 - val_loss: 1.8354 - val_accuracy: 0.6111\n",
      "Epoch 37/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.2619 - accuracy: 0.8919 - val_loss: 2.3674 - val_accuracy: 0.5889\n",
      "Epoch 38/55\n",
      "23/23 [==============================] - 2s 83ms/step - loss: 0.2446 - accuracy: 0.8829 - val_loss: 2.1079 - val_accuracy: 0.6111\n",
      "Epoch 39/55\n",
      "23/23 [==============================] - 2s 82ms/step - loss: 0.2678 - accuracy: 0.8964 - val_loss: 2.3908 - val_accuracy: 0.5667\n",
      "Epoch 40/55\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.3128 - accuracy: 0.8919 - val_loss: 1.9804 - val_accuracy: 0.6000\n",
      "Epoch 41/55\n",
      "23/23 [==============================] - 2s 84ms/step - loss: 0.2374 - accuracy: 0.8874 - val_loss: 2.2652 - val_accuracy: 0.6111\n",
      "Epoch 42/55\n",
      "23/23 [==============================] - 2s 85ms/step - loss: 0.2151 - accuracy: 0.9189 - val_loss: 2.4422 - val_accuracy: 0.6333\n",
      "Epoch 43/55\n",
      "23/23 [==============================] - 2s 80ms/step - loss: 0.2570 - accuracy: 0.9009 - val_loss: 2.3509 - val_accuracy: 0.6556\n",
      "Epoch 44/55\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.1736 - accuracy: 0.9261 - val_loss: 3.1636 - val_accuracy: 0.6333\n",
      "Epoch 45/55\n",
      "23/23 [==============================] - 2s 71ms/step - loss: 0.2010 - accuracy: 0.9234 - val_loss: 2.6619 - val_accuracy: 0.6333\n",
      "Epoch 46/55\n",
      "23/23 [==============================] - 2s 70ms/step - loss: 0.1963 - accuracy: 0.9054 - val_loss: 2.8977 - val_accuracy: 0.6000\n",
      "Epoch 47/55\n",
      "23/23 [==============================] - 2s 74ms/step - loss: 0.2538 - accuracy: 0.9009 - val_loss: 2.4795 - val_accuracy: 0.6111\n",
      "Epoch 48/55\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.2485 - accuracy: 0.8964 - val_loss: 2.8877 - val_accuracy: 0.6444\n",
      "Epoch 49/55\n",
      "23/23 [==============================] - 2s 68ms/step - loss: 0.2550 - accuracy: 0.9054 - val_loss: 2.4805 - val_accuracy: 0.6556\n",
      "Epoch 50/55\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.1982 - accuracy: 0.9054 - val_loss: 2.3763 - val_accuracy: 0.6333\n",
      "Epoch 51/55\n",
      "23/23 [==============================] - 2s 76ms/step - loss: 0.1823 - accuracy: 0.9369 - val_loss: 2.1376 - val_accuracy: 0.6333\n",
      "Epoch 52/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.1845 - accuracy: 0.9234 - val_loss: 2.2011 - val_accuracy: 0.6444\n",
      "Epoch 53/55\n",
      "23/23 [==============================] - 2s 79ms/step - loss: 0.1488 - accuracy: 0.9369 - val_loss: 1.9737 - val_accuracy: 0.6667\n",
      "Epoch 54/55\n",
      "23/23 [==============================] - 2s 72ms/step - loss: 0.2176 - accuracy: 0.8874 - val_loss: 2.2571 - val_accuracy: 0.6556\n",
      "Epoch 55/55\n",
      "23/23 [==============================] - 2s 69ms/step - loss: 0.1704 - accuracy: 0.9369 - val_loss: 2.7075 - val_accuracy: 0.6444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23927de2e80>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"D:\\\\python\\\\guicore-alpha\\\\gui-core-alpha-70-30\\\\testing\"\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step - loss: 9.5015 - accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "nb_test_samples = 20\n",
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000001192092896"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "image/jpeg": {
       "height": 100,
       "width": 100
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(img_path, width=100, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
